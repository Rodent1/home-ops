---
version: "3"

x-task-vars: &task-vars
  cluster: "{{.cluster}}"
  node: "{{.node}}"
  ceph_disk: "{{.ceph_disk}}"
  ts: "{{.ts}}"
  jobName: "{{.jobName}}"

vars:
  waitForJobScript: "{{.ROOT_DIR}}/.taskfiles/Rook/scripts/wait.sh"
  ts: '{{now | date "150405"}}'
tasks:
  toolbox:
    desc: Exec into the rook-ceph toolbox
    interactive: true
    cmds:
      - kubectl -n rook-ceph exec -it $(kubectl -n rook-ceph get pod -l "app=rook-ceph-tools" -o jsonpath='{.items[0].metadata.name}') -- bash

  password:
    desc: Retrieve the rook-ceph password
    cmds:
      - kubectl -n rook-ceph get secret rook-ceph-dashboard-password -o jsonpath="{['data']['password']}" | base64 --decode | pbcopy && echo "Copied to clipboard"

  wipe-node-1:
    desc: Trigger a wipe of Rook-Ceph data on node "node-1"
    cmds:
      - task: wipe-disk
        vars:
          node: "{{.node}}"
          ceph_disk: "/dev/disk/by-id/nvme-KINGSTON_SNV2S1000G_50026B72831CA9D0"
      - task: wipe-data
        vars:
          node: "{{.node}}"
    vars:
      node: node-1

  wipe-node-2:
    desc: Trigger a wipe of Rook-Ceph data on node "node-2"
    cmds:
      - task: wipe-disk
        vars:
          node: "{{.node}}"
          ceph_disk: "/dev/disk/by-id/nvme-KINGSTON_SNV2S1000G_50026B72831CAA00"
      - task: wipe-data
        vars:
          node: "{{.node}}"
    vars:
      node: node-2

  wipe-node-3:
    desc: Trigger a wipe of Rook-Ceph data on node "node-3"
    cmds:
      - task: wipe-disk
        vars:
          node: "{{.node}}"
          ceph_disk: "/dev/disk/by-id/nvme-KINGSTON_SNV2S1000G_50026B72831CA96F"
      - task: wipe-data
        vars:
          node: "{{.node}}"
    vars:
      node: node-3

  wipe-worker-1:
    desc: Trigger a wipe of Rook-Ceph data on node "worker-1"
    cmds:
      - task: wipe-disk
        vars:
          node: "{{.node}}"
          ceph_disk: "/dev/disk/by-id/nvme-INTEL_SSDPEKNW010T8_BTNH916507DA1P0B"
      - task: wipe-data
        vars:
          node: "{{.node}}"
    vars:
      node: node-4

  wipe-worker-2:
    desc: Trigger a wipe of Rook-Ceph data on node "worker-2"
    cmds:
      - task: wipe-disk
        vars:
          node: "{{.node}}"
          ceph_disk: "/dev/disk/by-id/nvme-KINGSTON_SNV2S1000G_50026B728308EA85"
      - task: wipe-data
        vars:
          node: "{{.node}}"
    vars:
      node: node-5

  wipe-disk:
    desc: Wipe all remnants of rook-ceph from a given disk (ex. task rook:wipe-disk node=delta ceph_disk="/dev/nvme0n1")
    silent: true
    internal: true
    cmds:
      - envsubst < <(cat {{.wipeRookDiskJobTemplate}}) | kubectl --context {{.cluster}} apply -f -
      - bash {{.waitForJobScript}} {{.wipeCephDiskJobName}} default {{.cluster}}
      - kubectl --context {{.cluster}} -n default wait job/{{.wipeCephDiskJobName}} --for condition=complete --timeout=1m
      - kubectl --context {{.cluster}} -n default logs job/{{.wipeCephDiskJobName}} --container list
      - kubectl --context {{.cluster}} -n default delete job {{.wipeCephDiskJobName}}
    vars:
      cluster: '{{ or .cluster (fail "`cluster` is required") }}'
      node: '{{ or .node (fail "`node` is required") }}'
      ceph_disk: '{{ or .ceph_disk (fail "`ceph_disk` is required") }}'
      jobName: 'wipe-disk-{{- .node -}}'
      wipeRookDiskJobTemplate: "{{.ROOT_DIR}}/.taskfiles/Rook/templates/WipeDiskJob.tmpl.yaml"
    env: *task-vars
    preconditions:
      - sh: test -f {{.waitForJobScript}}
      - sh: test -f {{.wipeRookDiskJobTemplate}}

  wipe-data:
    desc: Wipe all remnants of rook-ceph from a given disk (ex. task rook:wipe-data node=delta)
    silent: true
    internal: true
    cmds:
      - envsubst < <(cat {{.wipeRookDataJobTemplate}}) | kubectl --context {{.cluster}} apply -f -
      - bash {{.waitForJobScript}} {{.wipeRookDataJobName}} default {{.cluster}}
      - kubectl --context {{.cluster}} -n default wait job/{{.wipeRookDataJobName}} --for condition=complete --timeout=1m
      - kubectl --context {{.cluster}} -n default logs job/{{.wipeRookDataJobName}} --container list
      - kubectl --context {{.cluster}} -n default delete job {{.wipeRookDataJobName}}
    vars:
      cluster: '{{ or .cluster (fail "`cluster` is required") }}'
      node: '{{ or .node (fail "`node` is required") }}'
      jobName: "wipe-rook-data-{{- .node -}}-{{- .ts -}}"
      wipeRookDataJobTemplate: "{{.ROOT_DIR}}/.taskfiles/Rook/templates/WipeRookDataJob.tmpl.yaml"
    env: *task-vars
    preconditions:
      - sh: test -f {{.waitForJobScript}}
      - sh: test -f {{.wipeRookDataJobTemplate}}
